import requests
from bs4 import BeautifulSoup
import xml.etree.ElementTree as ET

def get_product_pages(sitemap_url):
    """
    Fetches and parses the sitemap to extract URLs of product pages.

    Args:
    sitemap_url (str): The URL of the sitemap.

    Returns:
    list: A list of URLs found in the sitemap.
    """
    response = requests.get(sitemap_url)
    sitemap_xml = response.text
    root = ET.fromstring(sitemap_xml)
    urls = [url[0].text for url in root]
    return urls

def extract_image_urls(page_url):
    """
    Scrapes a product page for image URLs.

    Args:
    page_url (str): The URL of the product page.

    Returns:
    list: A list of image URLs found on the page.
    """
    response = requests.get(page_url)
    soup = BeautifulSoup(response.content, 'html.parser')
    images = soup.find_all('img')
    image_urls = [img['src'] for img in images if 'src' in img.attrs]
    return image_urls

def write_to_xml(filename, data):
    """
    Writes provided data to an XML file.

    Args:
    filename (str): The name of the XML file to write to.
    data (list): The data to write to the XML file.
    """
    root = ET.Element("root")
    for page, image_urls in data.items():
        page_element = ET.SubElement(root, "page")
        page_element.text = page
        for url in image_urls:
            url_element = ET.SubElement(page_element, "image_url")
            url_element.text = url

    tree = ET.ElementTree(root)
    tree.write(filename, xml_declaration=True, encoding='utf-8')

def main():
    """
    Main function to execute the script.
    """
    sitemap_url = 'INSERT PRODUCT SITE MAP HERE'  # Replace with your sitemap URL
    product_pages = get_product_pages(sitemap_url)

    output_data = {}
    for page in product_pages:
        image_urls = extract_image_urls(page)
        output_data[page] = image_urls

    write_to_xml('output.xml', output_data)

if __name__ == "__main__":
    main()
